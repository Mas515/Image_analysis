{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/anaconda3/envs/New_environment220920/lib/python3.8/site-packages (0.8.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#No need to run again\n",
    "# pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown #1. Install the dependencies \n",
    "#dependency conflict \n",
    "#DEFINING THE FUNCTIONS\n",
    "\n",
    "from tabulate import tabulate\n",
    "from astropy.visualization import simple_norm\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.filters\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "import shutil \n",
    "import zipfile\n",
    "from tifffile import imread, imsave\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Structural similarity (SSIM) index for measuring image quality #can probably change the sigma\n",
    "def ssim(img1, img2):\n",
    "  return structural_similarity(img1,img2,data_range=1.,full=True, gaussian_weights=True, use_sample_covariance=False, sigma=1.5)\n",
    "\n",
    "\n",
    "def normalize(x, pmin=3, pmax=99.8, axis=None, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    \"\"\"This function is adapted from Martin Weigert\"\"\"\n",
    "    \"\"\"Percentile-based image normalization.\"\"\"\n",
    "\n",
    "    mi = np.percentile(x,pmin,axis=axis,keepdims=True)\n",
    "    ma = np.percentile(x,pmax,axis=axis,keepdims=True)\n",
    "    return normalize_mi_ma(x, mi, ma, clip=clip, eps=eps, dtype=dtype)\n",
    "\n",
    "\n",
    "def normalize_mi_ma(x, mi, ma, clip=False, eps=1e-20, dtype=np.float32):#dtype=np.float32\n",
    "    \"\"\"This function is adapted from Martin Weigert\"\"\"\n",
    "    if dtype is not None:\n",
    "        x   = x.astype(dtype,copy=False)\n",
    "        mi  = dtype(mi) if np.isscalar(mi) else mi.astype(dtype,copy=False)\n",
    "        ma  = dtype(ma) if np.isscalar(ma) else ma.astype(dtype,copy=False)\n",
    "        eps = dtype(eps)\n",
    "\n",
    "    try:\n",
    "        import numexpr\n",
    "        x = numexpr.evaluate(\"(x - mi) / ( ma - mi + eps )\")\n",
    "    except ImportError:\n",
    "        x =                   (x - mi) / ( ma - mi + eps )\n",
    "\n",
    "    if clip:\n",
    "        x = np.clip(x,0,1)\n",
    "\n",
    "    return x\n",
    "\n",
    "def norm_minmse(gt, x, normalize_gt=True):\n",
    "    \"\"\"This function is adapted from Martin Weigert\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    normalizes and affinely scales an image pair such that the MSE is minimized  \n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    gt: ndarray\n",
    "        the ground truth image      \n",
    "    x: ndarray\n",
    "        the image that will be affinely scaled \n",
    "    normalize_gt: bool\n",
    "        set to True of gt image should be normalized (default)\n",
    "    Returns\n",
    "    -------\n",
    "    gt_scaled, x_scaled \n",
    "    \"\"\"\n",
    "    if normalize_gt:\n",
    "        gt = normalize(gt, 0.1, 99.9, clip=False).astype(np.float32, copy = False)\n",
    "    x = x.astype(np.float32, copy=False) - np.mean(x)    \n",
    "    gt = gt.astype(np.float32, copy=False) - np.mean(gt)    \n",
    "    scale = np.cov(x.flatten(), gt.flatten())[0, 1] / np.var(x.flatten())\n",
    "    return gt, scale * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 11, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 11, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 12, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 12, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 12, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 11, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 12, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 11, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 11, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(21, 12, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "#@markdown #5. Choose the folders that contain the data to analyse and run to load the data. \n",
    "#The source folder must contain both the unprocessed and processed file, or run it twice on both folders\n",
    "#Solution here running on the raw data\n",
    "#separate output folder\n",
    "\n",
    "# Source_folder = \"/Users/secchim/Downloads/CellProfiler/movie_processing/2_channel_split_tif\" #@param{type:\"string\"}\n",
    "Source_folder = \"/Users/secchim/Downloads/CellProfiler/movie_processing/2_channel_split_tif_old\" #@param{type:\"string\"}\n",
    "# Source_folder = \"/Users/secchim/Downloads/CellProfiler/movies2_apply\" #@param{type:\"string\"}\n",
    "Result_folder = \"/Users/secchim/Downloads/CellProfiler/movie_processing/drift_assessment\" #@param{type:\"string\"}\n",
    "\n",
    "Analysis_type = \"Z-slice\" #@param [\"Max_projection\", \"Z-slice\"]\n",
    "\n",
    "Reference_Frame = \"Previous\" #@param [\"First\", \"Previous\"]\n",
    "\n",
    "\n",
    "#@markdown ##If not Max_projection, choose the Z plane to analyse\n",
    "Z_plane =  5#@param {type:\"number\"}\n",
    "\n",
    "# -------------------------------- Load the stack --------------------------------\n",
    "\n",
    "# random_choice=random.choice(os.listdir(Source_folder))\n",
    "for i in os.listdir(Source_folder):\n",
    "  # if i.endswith('Ch1.tif'):\n",
    "  if i.endswith('Ch2.tif') or i.endswith('xyzCorrected.tif'):\n",
    "    stack = imread(Source_folder+\"/\"+i)\n",
    "\n",
    "    print(stack.shape)\n",
    "\n",
    "    if Reference_Frame == \"Previous\":           \n",
    "      print('The Previous frame will be used as a reference')\n",
    "\n",
    "    if Reference_Frame == \"First\": \n",
    "      print('The First frame will be used as a reference')\n",
    "\n",
    "\n",
    "    # perform the max projection\n",
    "\n",
    "    if Analysis_type == \"Max_projection\":\n",
    "      #make max projection\n",
    "      maxproj = np.max(stack[:,:,:,:],axis = 1)\n",
    "      print('---------------------------')\n",
    "      print('max projection shape', maxproj.shape)\n",
    "\n",
    "\n",
    "    if Analysis_type == \"Z-slice\":\n",
    "      maxproj = stack[:,Z_plane,:,:]\n",
    "\n",
    "      print('---------------------------')\n",
    "      print('Stack shape:', maxproj.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # #Display one image\n",
    "\n",
    "    # f=plt.figure(figsize=(16,8))\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.imshow(maxproj[0], norm=simple_norm(maxproj[0], percent = 99), interpolation='nearest')\n",
    "\n",
    "    # plt.axis('off')\n",
    "    # plt.title('First frame');\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.imshow(maxproj[1], norm=simple_norm(maxproj[1], percent = 99), interpolation='nearest')\n",
    "    # plt.axis('off')\n",
    "    # plt.title('Second frame');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown #4. Process the raw data\n",
    "\n",
    "import csv\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "if Analysis_type == \"Max_projection\":\n",
    "  Z_plane = \"\"\n",
    "\n",
    "for i in os.listdir(Source_folder):\n",
    "  if not os.path.isdir(os.path.join(Source_folder,i)):\n",
    "    if i.endswith('Ch2.tif') or i.endswith('xyzCorrected.tif'): # removed xyz_corrected in the scenario where the raw and corrected files are in different folders\n",
    "    # if i.endswith('Ch1.tif'):#Ch2\n",
    "      print('Running QC on: '+i)\n",
    "      if i.startswith('VWF') and i.endswith('.tif'): #added that line because one hidden file was not tif in the folder\n",
    "        stack = imread(Source_folder+\"/\"+i)\n",
    "\n",
    "        if Analysis_type == \"Max_projection\":\n",
    "      \n",
    "          maxproj = np.max(stack[:,:,:,:],axis = 1)\n",
    "\n",
    "        if Analysis_type == \"Z-slice\":\n",
    "          maxproj = stack[:,Z_plane,:,:]\n",
    "\n",
    "    # Open and create the csv file that will contain all the QC metrics\n",
    "        with open(Result_folder+\"/\"+\"QC_metrics_\"+i+\"_\"+Analysis_type+str(Z_plane)+\"_\"+Reference_Frame+\".csv\", \"w\", newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "        # Write the header in the csv file\n",
    "            writer.writerow([\"image #\",\"Z plane\",\"Z plane + 1\", \"mSSIM\", \"NRMSE\", \"PSNR\", \"Pearson coefficient\"])  \n",
    "\n",
    "            # Initialize the lists\n",
    "            Z_plane_list = []\n",
    "            ssim_score_list = []\n",
    "            Pearson_correlation_coefficient_list = []\n",
    "              \n",
    "        # Let's loop through the provided dataset in the QC folders\n",
    "\n",
    "            for z in range(maxproj.shape[0]-1):\n",
    "\n",
    "              Z_plane_list.append(z)            \n",
    "          # -------------------------------- Load the data --------------------------------\n",
    "              if Reference_Frame == \"Previous\":           \n",
    "                test_GT = maxproj[z+1]                     \n",
    "                test_source = maxproj[z]\n",
    "\n",
    "              if Reference_Frame == \"First\":           \n",
    "                test_GT = maxproj[z+1]                     \n",
    "                test_source = maxproj[0]\n",
    "\n",
    "          # Normalize the images wrt each other by minimizing the MSE between GT and Source image\n",
    "              test_GT_norm,test_source_norm = norm_minmse(test_GT, test_source, normalize_gt=True)\n",
    "\n",
    "          # -------------------------------- Calculate the metric maps and save them --------------------------------\n",
    "\n",
    "          # Calculate the SSIM maps #structural similarity index\n",
    "              index_SSIM_GTvsSource, img_SSIM_GTvsSource = ssim(test_GT_norm, test_source_norm)\n",
    "\n",
    "              ssim_score_list.append(index_SSIM_GTvsSource)\n",
    "\n",
    "          #Save ssim_maps\n",
    "\n",
    "                #img_SSIM_GTvsSource_8bit = (img_SSIM_GTvsSource* 255).astype(\"uint8\")\n",
    "                #io.imsave(QC_model_path+'/'+QC_model_name+\"/Quality Control/\"+str(checkpoints)+\"/SSIM_GTvsSource_\"+shortname_no_PNG+'.tif',img_SSIM_GTvsSource_8bit)\n",
    "          \n",
    "          # Calculate the Root Squared Error (RSE) maps\n",
    "              img_RSE_GTvsSource = np.sqrt(np.square(test_GT_norm - test_source_norm))\n",
    "\n",
    "          # Save SE maps\n",
    "                #img_RSE_GTvsSource_8bit = (img_RSE_GTvsSource* 255).astype(\"uint8\")\n",
    "                #io.imsave(QC_model_path+'/'+QC_model_name+\"/Quality Control/\"+str(checkpoints)+\"/RSE_GTvsSource_\"+shortname_no_PNG+'.tif',img_RSE_GTvsSource_8bit)\n",
    "\n",
    "\n",
    "          # -------------------------------- Calculate the RSE metrics and save them --------------------------------\n",
    "\n",
    "          # Normalised Root Mean Squared Error (here it's valid to take the mean of the image)\n",
    "              NRMSE_GTvsSource = np.sqrt(np.mean(img_RSE_GTvsSource))\n",
    "            \n",
    "          # We can also measure the peak signal to noise ratio between the images\n",
    "              PSNR_GTvsSource = psnr(test_GT_norm,test_source_norm,data_range=1.0)\n",
    "\n",
    "\n",
    "              cm1 = np.corrcoef(test_GT_norm.flat, test_source_norm.flat) #outputs a flat number\n",
    "              r1 = cm1[0, 1]\n",
    "              Pearson_correlation_coefficient_list.append(r1)\n",
    "\n",
    "              writer.writerow([i,str(z),str(z+1),str(index_SSIM_GTvsSource),str(NRMSE_GTvsSource),str(PSNR_GTvsSource),str(r1)])\n",
    "\n",
    "  # All data is now processed saved\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown #3. Choose the folders that contain the data to analyse and run to load the data. \n",
    "#The source folder must contain both the unprocessed and processed file, or run it twice on both folders\n",
    "#Here running on the processed files\n",
    "#separate output folder\n",
    "\n",
    "Source_folder = \"/Users/secchim/Downloads/CellProfiler/movie_processing/4_drift_corrected\" #@param{type:\"string\"}\n",
    "# Source_folder = \"/Volumes/LUIS1_MS/Raw_Data/imaging/movie_processing/4_drift_corrected\" #@param{type:\"string\"}\n",
    "# Source_folder = \"/Users/secchim/Downloads/CellProfiler/movies2_apply\" #@param{type:\"string\"}\n",
    "Result_folder = \"/Users/secchim/Downloads/CellProfiler/movie_processing/drift_assessment\" #@param{type:\"string\"}\n",
    "\n",
    "Analysis_type = \"Z-slice\" #@param [\"Max_projection\", \"Z-slice\"]\n",
    "\n",
    "Reference_Frame = \"Previous\" #@param [\"First\", \"Previous\"]\n",
    "\n",
    "\n",
    "#@markdown ##If not Max_projection, choose the Z plane to analyse\n",
    "Z_plane =  5#@param {type:\"number\"}\n",
    "\n",
    "# -------------------------------- Load the stack --------------------------------\n",
    "\n",
    "# random_choice=random.choice(os.listdir(Source_folder))\n",
    "for i in os.listdir(Source_folder):\n",
    "  # if i.endswith('Ch1.tif'):\n",
    "  if i.endswith('Ch2.tif') or i.endswith('xyzCorrected.tif'):#\n",
    "    stack = imread(Source_folder+\"/\"+i)\n",
    "\n",
    "    print(stack.shape)\n",
    "\n",
    "    if Reference_Frame == \"Previous\":           \n",
    "      print('The Previous frame will be used as a reference')\n",
    "\n",
    "    if Reference_Frame == \"First\": \n",
    "      print('The First frame will be used as a reference')\n",
    "\n",
    "\n",
    "    # perform the max projection\n",
    "\n",
    "    if Analysis_type == \"Max_projection\":\n",
    "      #make max projection\n",
    "      maxproj = np.max(stack[:,:,:,:],axis = 1)\n",
    "      print('---------------------------')\n",
    "      print('max projection shape', maxproj.shape)\n",
    "\n",
    "\n",
    "    if Analysis_type == \"Z-slice\":\n",
    "      maxproj = stack[:,Z_plane,:,:]\n",
    "\n",
    "      print('---------------------------')\n",
    "      print('Stack shape:', maxproj.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # #Display one image\n",
    "\n",
    "    # f=plt.figure(figsize=(16,8))\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.imshow(maxproj[0], norm=simple_norm(maxproj[0], percent = 99), interpolation='nearest')\n",
    "\n",
    "    # plt.axis('off')\n",
    "    # plt.title('First frame');\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.imshow(maxproj[1], norm=simple_norm(maxproj[1], percent = 99), interpolation='nearest')\n",
    "    # plt.axis('off')\n",
    "    # plt.title('Second frame');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running QC on: VWF_048_MS220118_M3_movie2homeostasis_P6DP+_Ch2.tif\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 14, 509, 510)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (22, 509, 510)\n",
      "(21, 12, 512, 512)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (21, 512, 512)\n",
      "(22, 14, 509, 510)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (22, 509, 510)\n",
      "(22, 14, 509, 510)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (22, 509, 510)\n",
      "(22, 14, 509, 510)\n",
      "The Previous frame will be used as a reference\n",
      "---------------------------\n",
      "Stack shape: (22, 509, 510)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running QC on: VWF_109_MS230619_M2_movie_P6dp_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M2_movie_P8_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M2_movie_P7_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M2_movie_P2_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_109_MS230619_M1_movie_P5_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M2_movie_P9_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M1_movie_P12_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M2_movie_P11_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_109_MS230619_M1_movie_P4_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M1_movie_P11_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M1_movie_P14_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_109_MS230619_M2_movie_P7kuo_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_109_MS230619_M1_movie_P6_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_109_MS230619_M1_movie_P3_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M1_movie_P8_Ch1_xyzCorrected.tif\n",
      "Running QC on: VWF_107_MS230615_M1_movie_P10_Ch1_xyzCorrected.tif\n"
     ]
    }
   ],
   "source": [
    "#@markdown #6. Process the corrected data\n",
    "\n",
    "import csv\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "if Analysis_type == \"Max_projection\":\n",
    "  Z_plane = \"\"\n",
    "\n",
    "for i in os.listdir(Source_folder):\n",
    "  if not os.path.isdir(os.path.join(Source_folder,i)):\n",
    "    # if i.endswith('Ch1_xyzCorrected.tif'):\n",
    "    if i.endswith('Ch2.tif') or i.endswith('xyzCorrected.tif'):\n",
    "      print('Running QC on: '+i)\n",
    "      if i.startswith('VWF') and i.endswith('.tif'): #added that line because one hidden file was not tif in the folder\n",
    "        stack = imread(Source_folder+\"/\"+i)\n",
    "\n",
    "        if Analysis_type == \"Max_projection\":\n",
    "      \n",
    "          maxproj = np.max(stack[:,:,:,:],axis = 1)\n",
    "\n",
    "        if Analysis_type == \"Z-slice\":\n",
    "          maxproj = stack[:,Z_plane,:,:]\n",
    "\n",
    "    # Open and create the csv file that will contain all the QC metrics\n",
    "        with open(Result_folder+\"/\"+\"QC_metrics_\"+i+\"_\"+Analysis_type+str(Z_plane)+\"_\"+Reference_Frame+\".csv\", \"w\", newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "        # Write the header in the csv file\n",
    "            writer.writerow([\"image #\",\"Z plane\",\"Z plane + 1\", \"mSSIM\", \"NRMSE\", \"PSNR\", \"Pearson coefficient\"])  \n",
    "\n",
    "            # Initialize the lists\n",
    "            Z_plane_list = []\n",
    "            ssim_score_list = []\n",
    "            Pearson_correlation_coefficient_list = []\n",
    "              \n",
    "        # Let's loop through the provided dataset in the QC folders\n",
    "\n",
    "            for z in range(maxproj.shape[0]-1):\n",
    "\n",
    "              Z_plane_list.append(z)            \n",
    "          # -------------------------------- Load the data --------------------------------\n",
    "              if Reference_Frame == \"Previous\":           \n",
    "                test_GT = maxproj[z+1]                     \n",
    "                test_source = maxproj[z]\n",
    "\n",
    "              if Reference_Frame == \"First\":           \n",
    "                test_GT = maxproj[z+1]                     \n",
    "                test_source = maxproj[0]\n",
    "\n",
    "          # Normalize the images wrt each other by minimizing the MSE between GT and Source image\n",
    "              test_GT_norm,test_source_norm = norm_minmse(test_GT, test_source, normalize_gt=True)\n",
    "\n",
    "          # -------------------------------- Calculate the metric maps and save them --------------------------------\n",
    "\n",
    "          # Calculate the SSIM maps #structural similarity index\n",
    "              index_SSIM_GTvsSource, img_SSIM_GTvsSource = ssim(test_GT_norm, test_source_norm)\n",
    "\n",
    "              ssim_score_list.append(index_SSIM_GTvsSource)\n",
    "\n",
    "          #Save ssim_maps\n",
    "\n",
    "                #img_SSIM_GTvsSource_8bit = (img_SSIM_GTvsSource* 255).astype(\"uint8\")\n",
    "                #io.imsave(QC_model_path+'/'+QC_model_name+\"/Quality Control/\"+str(checkpoints)+\"/SSIM_GTvsSource_\"+shortname_no_PNG+'.tif',img_SSIM_GTvsSource_8bit)\n",
    "          \n",
    "          # Calculate the Root Squared Error (RSE) maps\n",
    "              img_RSE_GTvsSource = np.sqrt(np.square(test_GT_norm - test_source_norm))\n",
    "\n",
    "          # Save SE maps\n",
    "                #img_RSE_GTvsSource_8bit = (img_RSE_GTvsSource* 255).astype(\"uint8\")\n",
    "                #io.imsave(QC_model_path+'/'+QC_model_name+\"/Quality Control/\"+str(checkpoints)+\"/RSE_GTvsSource_\"+shortname_no_PNG+'.tif',img_RSE_GTvsSource_8bit)\n",
    "\n",
    "\n",
    "          # -------------------------------- Calculate the RSE metrics and save them --------------------------------\n",
    "\n",
    "          # Normalised Root Mean Squared Error (here it's valid to take the mean of the image)\n",
    "              NRMSE_GTvsSource = np.sqrt(np.mean(img_RSE_GTvsSource))\n",
    "            \n",
    "          # We can also measure the peak signal to noise ratio between the images\n",
    "              PSNR_GTvsSource = psnr(test_GT_norm,test_source_norm,data_range=1.0)\n",
    "\n",
    "\n",
    "              cm1 = np.corrcoef(test_GT_norm.flat, test_source_norm.flat) #outputs a flat number\n",
    "              r1 = cm1[0, 1]\n",
    "              Pearson_correlation_coefficient_list.append(r1)\n",
    "\n",
    "              writer.writerow([i,str(z),str(z+1),str(index_SSIM_GTvsSource),str(NRMSE_GTvsSource),str(PSNR_GTvsSource),str(r1)])\n",
    "\n",
    "  # All data is now processed saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_metrics_VWF_107_MS230615_M1_movie_P14_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M2_movie_P8_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M2_movie_P7_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_109_MS230619_M1_movie_P5_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M1_movie_P8_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_109_MS230619_M1_movie_P3_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M1_movie_P12_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_109_MS230619_M1_movie_P4_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M2_movie_P9_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M1_movie_P11_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_109_MS230619_M2_movie_P7kuo_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M2_movie_P11_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M2_movie_P2_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_109_MS230619_M2_movie_P6dp_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_109_MS230619_M1_movie_P6_Ch2.tif_Z-slice5_Previous.csv\n",
      "QC_metrics_VWF_107_MS230615_M1_movie_P10_Ch2.tif_Z-slice5_Previous.csv\n"
     ]
    }
   ],
   "source": [
    "#@markdown #. Showing and SAVING all \n",
    "##MATCHING UNCORRECTED AND FAST4DREG CORRECTED FILES\n",
    "\n",
    "Result_folder = \"/Users/secchim/Downloads/CellProfiler/movie_processing/drift_assessment\" #@param{type:\"string\"}\n",
    "\n",
    "QCResult_folder='/Users/secchim/Downloads/CellProfiler/movie_processing/drift_assessment_png'\n",
    "\n",
    "def show_QC_results(file1): #file1, file2, requires a list as an argument\n",
    "  # files= os.listdir(Result_folder)#\n",
    "  # file1=[i for i in os.listdir(Result_folder) if \"Corrected\" not in i] #if file already has corrected don't look at them , runs quicker than forloop, called list comprehension\n",
    "  df1 = pd.read_csv (Result_folder+\"/\"+file1)\n",
    "  ind=file1.index(\".tif\")\n",
    "  rep=file1[ind:]\n",
    "  file2=file1.replace(rep, '_xyzCorrected'+rep)\n",
    "  # file3=file1.replace(rep, 'drift'+rep)\n",
    "  df2 = pd.read_csv (Result_folder+\"/\"+file2)\n",
    "  # df3 = pd.read_csv (Result_folder+\"/\"+file3)\n",
    "  df1.set_index(\"image #\", inplace=True)\n",
    "  df2.set_index(\"image #\", inplace=True)\n",
    "  # df3.set_index(\"image #\", inplace=True)\n",
    "  # print(tabulate((df1,df2), headers='keys', tablefmt='psql'))\n",
    "\n",
    "  Z_plane_list1 = df1['Z plane + 1'].values.tolist()\n",
    "  Z_plane_list2 = df2['Z plane + 1'].values.tolist()\n",
    "  # Z_plane_list3 = df3['Z plane + 1'].values.tolist()\n",
    "  ssim_score_list1 = df1['mSSIM'].values.tolist()\n",
    "  ssim_score_list2 = df2['mSSIM'].values.tolist()\n",
    "  # ssim_score_list3 = df3['mSSIM'].values.tolist()\n",
    "  Pearson_correlation_coefficient_list1 = df1['Pearson coefficient'].values.tolist()\n",
    "  Pearson_correlation_coefficient_list2 = df2['Pearson coefficient'].values.tolist()\n",
    "  # Pearson_correlation_coefficient_list3 = df3['Pearson coefficient'].values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------- Display --------------------------------\n",
    "\n",
    "  plt.figure(figsize=(20,5))\n",
    "  plt.plot(Z_plane_list1, ssim_score_list1, label=\"SSIM_raw\")\n",
    "  plt.plot(Z_plane_list2, ssim_score_list2, label=\"SSIM_Fast4Dcorrected\")\n",
    "  # plt.plot(Z_plane_list3, ssim_score_list3, label=\"SSIM_ImageJcorrected\")\n",
    "  plt.title('Timepoints vs. SSIM')\n",
    "  plt.ylabel('SSIM')\n",
    "  plt.xlabel('Timepoints')\n",
    "  plt.legend()\n",
    "  # plt.savefig(full_QC_model_path+'/Quality Control/SSIMvsCheckpoint_data.png',bbox_inches='tight',pad_inches=0)\n",
    "  plt.savefig(QCResult_folder+(\"/\"+file1+'SSIMvsCheckpoint_data.png'),bbox_inches='tight',pad_inches=0)\n",
    "  #plt.show()\n",
    "  plt.close()\n",
    "\n",
    "  plt.figure(figsize=(20,5))\n",
    "  plt.plot(Z_plane_list1, Pearson_correlation_coefficient_list1, label=\"Pearson coefficient_raw\")\n",
    "  plt.plot(Z_plane_list2, Pearson_correlation_coefficient_list2, label=\"Pearson coefficient_Fast4Dcorrected\")\n",
    "  # plt.plot(Z_plane_list3, Pearson_correlation_coefficient_list3, label=\"Pearson coefficient_ImageJcorrected\")\n",
    "  plt.title('Timepoints vs. Pearson coefficient')\n",
    "  plt.ylabel('Pearson coefficient')\n",
    "  plt.xlabel('Timepoints')\n",
    "  plt.legend()\n",
    "#plt.savefig(full_QC_model_path+'/Quality Control/lpipsvsCheckpoint_data.png',bbox_inches='tight',pad_inches=0)\n",
    "  plt.savefig(QCResult_folder+(\"/\"+file1+'lpipsvsCheckpoint_data.png'),bbox_inches='tight',pad_inches=0)\n",
    " # plt.show()\n",
    "  plt.close()\n",
    "\n",
    "\n",
    "error_list=[]\n",
    "for i in os.listdir(Result_folder):\n",
    "  if (\".tif\" in i and \"Corrected\" not in i and \".DS_Store\" not in i): \n",
    "    # print(i)\n",
    "    try:\n",
    "      show_QC_results(i)\n",
    "      print(i)\n",
    "    except:\n",
    "      print(\"error with \"+i)\n",
    "      error_list.append(i)\n",
    "\n",
    "\n",
    "#vasculature P12 is the problem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "['QC_metrics_VWF_066_MS220522_M4_pmovie1_P5bigDP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie18_depletion_P11_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_043_MS211118_m1-p5_11_12_homeostasismovie_vasculature_P11_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_053_MS220209_M1_movie5depletion_P16DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220119_M1_homeostasis_movie_3_P16DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie11_depletion_P9_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220118_M3_movie2homeostasis_P13+_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M1_MOVIE3_P1DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_053_MS220209_M1_movie8depletion_P17kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M1_MOVIE3_P11DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie13_depletion_P14_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie13_depletion_P9_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P25_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P23_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220119_M1_homeostasis_movie_2_P18+_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220119_M1_homeostasis_movie_2_P17DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_043_MS211118_m1-p5_11_12_pltdepletionmovie2_P12_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie4homeostasis_P152kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_066_MS220522_M1_movie2_P4k_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_053_MS220209_M1_movie4depletion_P18kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_043_MS211125_m3-homeostasis_movie_M1_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M1_MOVIE3_P10_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_063_MS220428_m1_movie1_P15_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_043_MS211126_m4-pltdepletionmovie1_P7++_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_043_MS211126_m4-pltdepletionmovie2_P1<3_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie4homeostasis_P14_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220119_M1_homeostasis_movie_3_P18+_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie13_depletion_P11_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M1_MOVIECHECKSTAGE1_0_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie7depletion_P9kuo2_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie18_depletion_P14_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M1_MOVIE2_P11DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie20_depletion_P4_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie8depletion_P4kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie4homeostasis_P9_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_053_MS220209_M1_movie3depletion_P18kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie7depletion_P11kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_066_MS220519_M2_movie2_P6k_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie6depletion_P9kuo2_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_066_MS220519_M2_movie2_P18k_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie8depletion_P12DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie19_depletion_P4_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_053_MS220209_M1_movie8depletion_P26kuovascu_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie10depletion_P4kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie8depletion_P16kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P27_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_062_MS220420_M3_movie2_P14kuodp_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie8depletion_P11kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220119_M1_homeostasis_movie_3_P17DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_053_MS220209_M1_movie4depletion_P24kuomk_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_053_MS220209_M1_movie3depletion_P14partlygreen_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie4homeostasis_P10spot_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie7depletion_P16kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie10depletion_21green_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_063_MS220428_m2_movie1_P24MK_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie6depletion_P152kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie10depletion_P16kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220118_M3_movie3plt_P27+_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie4homeostasis_P11_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M2_movie_test2_P9_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie19_depletion_P10_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M1_MOVIE4_P17_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie4homeostasis_P7_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_049_MS220201_M1_Snap_movie8depletion_P9kuo2_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_043_MS211126_m4-homeostasismovie_2_P1<3_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_053_MS220209_M1_movie5depletion_P22kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P22_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_066_MS220522_M4_pmovie2_P3kuo_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_066_MS220522_M1_movie1_P7k_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M1_MOVIE3_P4GREENVESSEL_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_048_MS220120_M2_movie18_depletion_P4_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_066_MS220522_M1_movie2_P10DP_Ch2.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_060_MS220408_M1_MOVIE5_P16_Ch2.tif_Z-slice5_Previous.csv']\n"
     ]
    }
   ],
   "source": [
    "print(len(error_list))\n",
    "print(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QC_metrics_VWF_045_MS211208_M2_movie7_P27_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P25_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P23_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P27_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P21_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P26_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P25_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P23_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P26_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P21_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P26_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P21_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P27_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P25_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P23_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P22_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P19_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P25_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P26_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P26_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P19_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P22_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P19_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P25_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P27_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P19_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P24_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P25_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P27_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P22_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P27_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P19_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P19_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P26_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P24_Ch1_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P24_Ch2_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P19_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P27_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P24_Ch4_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P25_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P22_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P19_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P26_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P25_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie6_P23_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie3_P21_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie8_P26_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv', 'QC_metrics_VWF_045_MS211208_M2_movie7_P27_Ch3_xyzCorrected.tif_Z-slice5_Previous.csv']\n"
     ]
    }
   ],
   "source": [
    "Result_folder = \"/Users/secchim/Downloads/CellProfiler/QC2\" #@param{type:\"string\"}\n",
    "QCResult_folder='/Users/secchim/Downloads/CellProfiler/QC2png'\n",
    "\n",
    "print(os.listdir(Result_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell will return a list of movies that should be checked because pearson correlation is low\n",
    "\n",
    "\n",
    "for file1 in os.listdir(Result_folder):\n",
    "  if \".tif\" in file1 and \"Corrected\" not in file1: \n",
    "    ind=file1.index(\".tif\")\n",
    "    rep=file1[ind:]\n",
    "    file2=file1.replace(rep, '_xyzCorrected'+rep)\n",
    "    df2 = pd.read_csv (Result_folder+\"/\"+file2)\n",
    "\n",
    "    Pearson_correlation_coefficient_list2 = df2['Pearson coefficient'].values.tolist()\n",
    "        \n",
    "    for t in Pearson_correlation_coefficient_list2 :\n",
    "        if t<0.4:\n",
    "            print(file2)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell will move the movies that were better uncorrected into a new folder, move the movies that were better corrected into a new folder\n",
    "#then add xyzCorrected to the name of the movies that were better uncorrected => to allow downstream processing\n",
    "\n",
    "#Here Result_folder is the QC/ drift assessment folder #same as above\n",
    "#Here Split_folder is the split channel folder\n",
    "\n",
    "Split_folder=\"/Users/secchim/Downloads/CellProfiler/movie_processing/2_channel_split_tif\"\n",
    "\n",
    "for file1 in os.listdir(Result_folder):\n",
    "  if \".tif\" in file1 and \"Corrected\" not in file1: \n",
    "    ind=file1.index(\".tif\")\n",
    "    rep=file1[ind:]\n",
    "    file2=file1.replace(rep, '_xyzCorrected'+rep)\n",
    "    df1 = pd.read_csv (Result_folder+\"/\"+file1)\n",
    "    df2 = pd.read_csv (Result_folder+\"/\"+file2)\n",
    "\n",
    "    Pearson_correlation_coefficient_list2 = df2['Pearson coefficient'].values.tolist()\n",
    "    differential_pearson=sum(df2[\"Pearson coefficient\"]-df1[\"Pearson coefficient\"])/len(df2[\"Pearson coefficient\"])\n",
    "    if differential_pearson<0.05:\n",
    "      print(\"moving \"+file1)\n",
    "      os.rename(Split_folder+\"/\"+file1, Split_folder+\"/BetterUncorrected/\"+file2)\n",
    "      \n",
    "        \n",
    "    for t in Pearson_correlation_coefficient_list2 :\n",
    "        if t<0.4:\n",
    "            print(file2)\n",
    "            os.rename(Split_folder+\"/\"+file1, Split_folder+\"/BetterUncorrected/\"+file2)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('New_environment220920')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a63d56e76719a8fe6131e722e007a895818566ffc58d874af7d5e8fbf367b2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
